==========================================================AI=======================================================================
Assignment 1: Problem Space, Search and Control Strategies

1. Breadth First Search (BFS)
-----------------------------
from collections import deque

def bfs(graph, start):
    visited = set()
    queue = deque([start])
    while queue:
        node = queue.popleft()
        if node not in visited:
            print(node, end=" ")
            visited.add(node)
            queue.extend(graph[node] - visited)

graph = {
    'A': {'B','C'},
    'B': {'D','E'},
    'C': {'F'},
    'D': set(),
    'E': {'F'},
    'F': set()
}
bfs(graph, 'A')


2. Depth First Search (DFS)
---------------------------
def dfs(graph, start, visited=None):
    if visited is None:
        visited = set()
    print(start, end=" ")
    visited.add(start)
    for neighbor in graph[start]:
        if neighbor not in visited:
            dfs(graph, neighbor, visited)

dfs(graph, 'A')


3. A* Algorithm
--------------
from queue import PriorityQueue

def a_star(graph, start, goal, h):
    open_set = PriorityQueue()
    open_set.put((0, start))
    g = {start: 0}
    while not open_set.empty():
        _, current = open_set.get()
        if current == goal:
            print(f"Reached: {goal}")
            return
        for neighbor, cost in graph[current].items():
            temp_g = g[current] + cost
            if neighbor not in g or temp_g < g[neighbor]:
                g[neighbor] = temp_g
                f = temp_g + h[neighbor]
                open_set.put((f, neighbor))

graph = {
    'A': {'B':1, 'C':3},
    'B': {'D':1, 'E':5},
    'C': {'F':2},
    'D': {}, 'E': {'F':1}, 'F': {}
}
h = {'A':5, 'B':3, 'C':4, 'D':2, 'E':2, 'F':0}
a_star(graph, 'A', 'F', h)


4. Best First Search
---------------------
from queue import PriorityQueue

def best_first_search(graph, start, goal, h):
    visited = set()
    pq = PriorityQueue()
    pq.put((h[start], start))
    while not pq.empty():
        _, node = pq.get()
        if node == goal:
            print(f"Reached: {goal}")
            return
        if node not in visited:
            print(node, end=" ")
            visited.add(node)
            for neighbor in graph[node]:
                if neighbor not in visited:
                    pq.put((h[neighbor], neighbor))

graph = {
    'A': ['B','C'],
    'B': ['D','E'],
    'C': ['F'],
    'D': [], 'E': ['F'], 'F': []
}
h = {'A':5,'B':2,'C':4,'D':6,'E':1,'F':0}
best_first_search(graph, 'A', 'F', h)


5. AO* Algorithm
----------------
def aostar(node, graph, h):
    print("Processing:", node)
    if node not in graph or not graph[node]:
        return h[node]
    
    cost, path = float('inf'), None
    for option in graph[node]:
        current_cost = sum(h[child] for child in option[0]) + option[1]
        if current_cost < cost:
            cost = current_cost
            path = option[0]
    
    for child in path:
        h[child] = aostar(child, graph, h)
    
    h[node] = sum(h[child] for child in path)
    return h[node]

graph = {
    'A': [ (['B','C'], 1) ],
    'B': [ (['D','E'], 1) ],
    'C': [ (['F'], 1) ],
    'D': [], 'E': [], 'F': []
}
h = {'A':0,'B':0,'C':0,'D':1,'E':2,'F':3}
aostar('A', graph, h)


Assignment 3: Game Playing

1. Minimax
----------
def minimax(depth, node, isMax, scores):
    if depth == 2:
        return scores[node]
    if isMax:
        return max(minimax(depth+1, node*2, False, scores),
                   minimax(depth+1, node*2+1, False, scores))
    else:
        return min(minimax(depth+1, node*2, True, scores),
                   minimax(depth+1, node*2+1, True, scores))

scores = [3, 5, 2, 9]
print("Minimax result:", minimax(0, 0, True, scores))


2. Alpha Beta Pruning
----------------------
def alphabeta(depth, node, alpha, beta, isMax, scores):
    if depth == 2:
        return scores[node]
    if isMax:
        best = -999
        for i in range(2):
            val = alphabeta(depth+1, node*2+i, alpha, beta, False, scores)
            best = max(best, val)
            alpha = max(alpha, best)
            if beta <= alpha:
                break
        return best
    else:
        best = 999
        for i in range(2):
            val = alphabeta(depth+1, node*2+i, alpha, beta, True, scores)
            best = min(best, val)
            beta = min(beta, best)
            if beta <= alpha:
                break
        return best

print("Alpha-Beta result:", alphabeta(0, 0, -999, 999, True, scores))


3. Naive Bayes
--------------
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split

X = [[1,1,1],[0,1,1],[1,0,0],[0,0,1],[1,1,1],[1,0,1],[0,1,1]]
y = [1, 0, 1, 0, 1, 1, 0]

model = GaussianNB()
model.fit(X, y)
print("Prediction for [1,0,0]:", model.predict([[1,0,0]]))


4. Tower of Hanoi
-----------------
def hanoi(n, source, temp, target):
    if n == 1:
        print(f"Move disk 1 from {source} to {target}")
        return
    hanoi(n-1, source, target, temp)
    print(f"Move disk {n} from {source} to {target}")
    hanoi(n-1, temp, source, target)

hanoi(3, 'A', 'B', 'C')


Assignment 4: NLP and Neural Networks

1. AND Gate
-----------
import numpy as np

X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[0],[0],[1]])

weights = np.array([[1],[1]])
output = np.dot(X, weights) >= 2
print("AND Gate Output:\n", output.astype(int))


2. OR Gate
----------
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[1]])

weights = np.array([[1],[1]])
output = np.dot(X, weights) >= 1
print("OR Gate Output:\n", output.astype(int))


3. Perceptron for Bipolar Inputs
--------------------------------
X = np.array([[-1,-1], [-1,1], [1,-1], [1,1]])
y = np.array([-1, -1, -1, 1])

w = np.zeros(2)
b = 0
lr = 1

for _ in range(10):
    for i in range(4):
        output = np.dot(X[i], w) + b
        if y[i] * output <= 0:
            w += lr * y[i] * X[i]
            b += lr * y[i]

print("Weights:", w, "Bias:", b)


4. TLN
------
def TLN(x1, x2):
    w1, w2, threshold = 1, 1, 1.5
    return 1 if (x1*w1 + x2*w2) >= threshold else 0

for x in [(0,0), (0,1), (1,0), (1,1)]:
    print(f"Input {x} → Output: {TLN(*x)}")


5. 3-Layer Neural Network with Keras
------------------------------------
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

X = np.array([[0,1,1], [1,0,0], [1,0,1], [0,0,1], [1,1,1], [1,0,1], [0,1,1]])
y = np.array([[1], [0], [1], [0], [1], [1], [0]])

model = Sequential()
model.add(Dense(4, input_dim=3, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

for epochs in [10, 100, 10000]:
    model.fit(X, y, epochs=epochs, verbose=0)
    _, acc = model.evaluate(X, y, verbose=0)
    print(f"Accuracy after {epochs} epochs: {acc:.2f}")

print("Test [1,0,0] →", model.predict(np.array([[1,0,0]])))



==================================================================DMT===================================================================================
Assignment 1: Basic Pandas and NumPy Programming
------------------------------------------------
1. Get NumPy version and build config:
import numpy as np
print(np.__version__)
np.show_config()

2. Get help on add function:
help(np.add)

3. Check if none of the array elements is zero:
print(np.all(np.array([1, 2, 3])))

4. Check finiteness of elements:
print(np.isfinite([1, 0, np.nan, np.inf]))

5. Element-wise comparison of arrays:
a, b = np.array([1, 2, 3]), np.array([3, 2, 1])
print(a > b, a >= b, a < b, a <= b)

6. Create array and memory size:
arr = np.array([1, 7, 13, 105])
print(arr.nbytes)

7. Even integers from 30 to 70:
print(np.arange(30, 71, 2))

8. 3x3 Identity matrix:
print(np.identity(3))

9. Random number between 0 and 1:
print(np.random.rand())

10. 15 random numbers from normal distribution:
print(np.random.randn(15))

11. Vector from 15 to 55 excluding first and last:
print(np.arange(15, 56)[1:-1])

12. Create and iterate 3x4 array:
a = np.arange(12).reshape(3,4)
for row in a: print(row)

13. Vector of length 5 with random ints 0-10:
print(np.random.randint(0, 11, 5))

14. Convert NumPy array to Pandas series:
import pandas as pd
print(pd.Series([10, 20, 30, 40, 50]))

15. Extract day, week info from date strings:
dates = pd.to_datetime(pd.Series(['2023-01-01', '2023-12-31']))
print(dates.dt.day, dates.dt.dayofyear, dates.dt.isocalendar().week, dates.dt.dayofweek)

16. Capitalize first and last letter:
s = pd.Series(['hello world', 'my name is'])
print(s.apply(lambda x: ' '.join([w[:1].upper()+w[1:-1]+w[-1:].upper() for w in x.split()])))

17. Descriptive stats:
s = pd.Series(np.random.randn(100))
print(s.min(), s.quantile(.25), s.median(), s.quantile(.75), s.max())

18. Mean and std deviation:
data = pd.Series([1,2,3,4,5,6,7,8,9,5,3])
print(data.mean(), data.std())

19. Euclidean distance:
from scipy.spatial.distance import euclidean
s1 = pd.Series([1, 2, 3])
s2 = pd.Series([4, 5, 6])
print(euclidean(s1, s2))

20. All Sundays in a year:
sundays = pd.date_range(start='2023-01-01', end='2023-12-31', freq='W-SUN')
print(sundays)


Assignment 2: Data Pre-Processing and Preparation
-------------------------------------------------
1. Read StudentsPerformance.csv and basic info:
df = pd.read_csv('StudentsPerformance.csv')
print(df.shape)
print(df.head())
print(df.sample(5))
print(df.columns, len(df.columns))

2a. Bar plot for Iris:
df = pd.read_csv('iris.csv')
df['species'].value_counts().plot(kind='bar')
plt.show()

2b. Histogram for Iris:
for sp in df['species'].unique():
  df[df['species']==sp].hist(alpha=0.5)
plt.show()

3. DataFrame with nulls, remove them:
data = pd.DataFrame({
  'Name': ['A', 'B', None, 'D', 'A', '', None, 'F', 'G', 'H'],
  'Salary': [10000, None, 15000, '', 10000, 12000, 13000, None, 10000, 14000],
  'Dept': ['IT', 'HR', None, 'HR', 'IT', '', None, 'IT', 'HR', 'IT']
})
data = data.dropna().replace('', pd.NA).dropna()
print(data)


Assignment 3: Frequent Item Set Mining
--------------------------------------
1. Apriori on groceries.csv:
from mlxtend.frequent_patterns import apriori, association_rules
df = pd.read_csv('groceries.csv', header=None)
transactions = df.stack().groupby(level=0).apply(list)
from mlxtend.preprocessing import TransactionEncoder
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df = pd.DataFrame(te_ary, columns=te.columns_)
freq_items = apriori(df, min_support=0.004, use_colnames=True)
rules = association_rules(freq_items, metric='lift', min_threshold=3)
rules = rules[rules['confidence'] >= 0.2]
print(rules[['support', 'confidence', 'lift']])

2. Apriori on Market_Basket_Optimisation.csv:
df = pd.read_csv('Market_Basket_Optimisation.csv', header=None)
transactions = df.stack().groupby(level=0).apply(list)
te = TransactionEncoder()
df = pd.DataFrame(te.fit(transactions).transform(transactions), columns=te.columns_)
freq_items = apriori(df, min_support=0.004, use_colnames=True)
rules = association_rules(freq_items, metric='lift', min_threshold=3)
print(rules[['support', 'confidence', 'lift']])


Assignment 4: Classification and Prediction
-------------------------------------------
1. Decision Tree on iris.csv:
df = pd.read_csv('iris.csv')
from sklearn.tree import DecisionTreeClassifier
X = df.iloc[:, :-1]; y = df.iloc[:, -1]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y)
clf = DecisionTreeClassifier(criterion='entropy')
clf.fit(X_train, y_train)
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, clf.predict(X_test)))

2. Naive Bayes on user_data.csv:
df = pd.read_csv('user_data.csv')
from sklearn.naive_bayes import GaussianNB
X = df.iloc[:, :-1]; y = df.iloc[:, -1]
X_train, X_test, y_train, y_test = train_test_split(X, y)
model = GaussianNB()
model.fit(X_train, y_train)
print(accuracy_score(y_test, model.predict(X_test)))

3. Simple Linear Regression on salary_data.csv:
df = pd.read_csv('salary_data.csv')
from sklearn.linear_model import LinearRegression
X = df[['YearsExperience']]
y = df['Salary']
X_train, X_test, y_train, y_test = train_test_split(X, y)
model = LinearRegression()
model.fit(X_train, y_train)
import matplotlib.pyplot as plt
plt.scatter(X_test, y_test)
plt.plot(X_test, model.predict(X_test))
plt.show()


Assignment 5: Clustering
------------------------
1. K-Means on income.csv:
df = pd.read_csv('income.csv')
from sklearn.cluster import KMeans
X = df[['Income', 'Age']]
kmeans = KMeans(n_clusters=3)
df['Cluster'] = kmeans.fit_predict(X)
plt.scatter(X['Income'], X['Age'], c=df['Cluster'])
plt.xlabel('Income'); plt.ylabel('Age')
plt.title('K-Means Clustering')
plt.show()
