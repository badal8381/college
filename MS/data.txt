==========================================================AI=======================================================================
Assignment 1: Problem Space, Search and Control Strategies

1. Breadth First Search (BFS)
-----------------------------
from collections import deque

def bfs(graph, start):
    visited = set()
    queue = deque([start])
    while queue:
        node = queue.popleft()
        if node not in visited:
            print(node, end=" ")
            visited.add(node)
            queue.extend(graph[node] - visited)

graph = {
    'A': {'B','C'},
    'B': {'D','E'},
    'C': {'F'},
    'D': set(),
    'E': {'F'},
    'F': set()
}
bfs(graph, 'A')


2. Depth First Search (DFS)
---------------------------
def dfs(graph, start, visited=None):
    if visited is None:
        visited = set()
    print(start, end=" ")
    visited.add(start)
    for neighbor in graph[start]:
        if neighbor not in visited:
            dfs(graph, neighbor, visited)

dfs(graph, 'A')


3. A* Algorithm
--------------
from queue import PriorityQueue

def a_star(graph, start, goal, h):
    open_set = PriorityQueue()
    open_set.put((0, start))
    g = {start: 0}
    while not open_set.empty():
        _, current = open_set.get()
        if current == goal:
            print(f"Reached: {goal}")
            return
        for neighbor, cost in graph[current].items():
            temp_g = g[current] + cost
            if neighbor not in g or temp_g < g[neighbor]:
                g[neighbor] = temp_g
                f = temp_g + h[neighbor]
                open_set.put((f, neighbor))

graph = {
    'A': {'B':1, 'C':3},
    'B': {'D':1, 'E':5},
    'C': {'F':2},
    'D': {}, 'E': {'F':1}, 'F': {}
}
h = {'A':5, 'B':3, 'C':4, 'D':2, 'E':2, 'F':0}
a_star(graph, 'A', 'F', h)


4. Best First Search
---------------------
from queue import PriorityQueue

def best_first_search(graph, start, goal, h):
    visited = set()
    pq = PriorityQueue()
    pq.put((h[start], start))
    while not pq.empty():
        _, node = pq.get()
        if node == goal:
            print(f"Reached: {goal}")
            return
        if node not in visited:
            print(node, end=" ")
            visited.add(node)
            for neighbor in graph[node]:
                if neighbor not in visited:
                    pq.put((h[neighbor], neighbor))

graph = {
    'A': ['B','C'],
    'B': ['D','E'],
    'C': ['F'],
    'D': [], 'E': ['F'], 'F': []
}
h = {'A':5,'B':2,'C':4,'D':6,'E':1,'F':0}
best_first_search(graph, 'A', 'F', h)


5. AO* Algorithm
----------------
def aostar(node, graph, h):
    print("Processing:", node)
    if node not in graph or not graph[node]:
        return h[node]
    
    cost, path = float('inf'), None
    for option in graph[node]:
        current_cost = sum(h[child] for child in option[0]) + option[1]
        if current_cost < cost:
            cost = current_cost
            path = option[0]
    
    for child in path:
        h[child] = aostar(child, graph, h)
    
    h[node] = sum(h[child] for child in path)
    return h[node]

graph = {
    'A': [ (['B','C'], 1) ],
    'B': [ (['D','E'], 1) ],
    'C': [ (['F'], 1) ],
    'D': [], 'E': [], 'F': []
}
h = {'A':0,'B':0,'C':0,'D':1,'E':2,'F':3}
aostar('A', graph, h)


Assignment 3: Game Playing

1. Minimax
----------
def minimax(depth, node, isMax, scores):
    if depth == 2:
        return scores[node]
    if isMax:
        return max(minimax(depth+1, node*2, False, scores),
                   minimax(depth+1, node*2+1, False, scores))
    else:
        return min(minimax(depth+1, node*2, True, scores),
                   minimax(depth+1, node*2+1, True, scores))

scores = [3, 5, 2, 9]
print("Minimax result:", minimax(0, 0, True, scores))


2. Alpha Beta Pruning
----------------------
def alphabeta(depth, node, alpha, beta, isMax, scores):
    if depth == 2:
        return scores[node]
    if isMax:
        best = -999
        for i in range(2):
            val = alphabeta(depth+1, node*2+i, alpha, beta, False, scores)
            best = max(best, val)
            alpha = max(alpha, best)
            if beta <= alpha:
                break
        return best
    else:
        best = 999
        for i in range(2):
            val = alphabeta(depth+1, node*2+i, alpha, beta, True, scores)
            best = min(best, val)
            beta = min(beta, best)
            if beta <= alpha:
                break
        return best

print("Alpha-Beta result:", alphabeta(0, 0, -999, 999, True, scores))


3. Naive Bayes
--------------
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split

X = [[1,1,1],[0,1,1],[1,0,0],[0,0,1],[1,1,1],[1,0,1],[0,1,1]]
y = [1, 0, 1, 0, 1, 1, 0]

model = GaussianNB()
model.fit(X, y)
print("Prediction for [1,0,0]:", model.predict([[1,0,0]]))


4. Tower of Hanoi
-----------------
def hanoi(n, source, temp, target):
    if n == 1:
        print(f"Move disk 1 from {source} to {target}")
        return
    hanoi(n-1, source, target, temp)
    print(f"Move disk {n} from {source} to {target}")
    hanoi(n-1, temp, source, target)

hanoi(3, 'A', 'B', 'C')


Assignment 4: NLP and Neural Networks

1. AND Gate
-----------
import numpy as np

X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[0],[0],[1]])

weights = np.array([[1],[1]])
output = np.dot(X, weights) >= 2
print("AND Gate Output:\n", output.astype(int))


2. OR Gate
----------
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[1]])

weights = np.array([[1],[1]])
output = np.dot(X, weights) >= 1
print("OR Gate Output:\n", output.astype(int))


3. Perceptron for Bipolar Inputs
--------------------------------
X = np.array([[-1,-1], [-1,1], [1,-1], [1,1]])
y = np.array([-1, -1, -1, 1])

w = np.zeros(2)
b = 0
lr = 1

for _ in range(10):
    for i in range(4):
        output = np.dot(X[i], w) + b
        if y[i] * output <= 0:
            w += lr * y[i] * X[i]
            b += lr * y[i]

print("Weights:", w, "Bias:", b)


4. TLN
------
def TLN(x1, x2):
    w1, w2, threshold = 1, 1, 1.5
    return 1 if (x1*w1 + x2*w2) >= threshold else 0

for x in [(0,0), (0,1), (1,0), (1,1)]:
    print(f"Input {x} → Output: {TLN(*x)}")


5. 3-Layer Neural Network with Keras
------------------------------------
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

X = np.array([[0,1,1], [1,0,0], [1,0,1], [0,0,1], [1,1,1], [1,0,1], [0,1,1]])
y = np.array([[1], [0], [1], [0], [1], [1], [0]])

model = Sequential()
model.add(Dense(4, input_dim=3, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

for epochs in [10, 100, 10000]:
    model.fit(X, y, epochs=epochs, verbose=0)
    _, acc = model.evaluate(X, y, verbose=0)
    print(f"Accuracy after {epochs} epochs: {acc:.2f}")

print("Test [1,0,0] →", model.predict(np.array([[1,0,0]])))
